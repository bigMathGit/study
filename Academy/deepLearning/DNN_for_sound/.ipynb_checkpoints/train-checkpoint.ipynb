{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "#from matplotlib.pyplot import specgram\n",
    "#from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "plt.rcParams['figure.titlesize'] = 13\n",
    "\n",
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    return mfccs,chroma,mel,contrast,tonnetz\n",
    "\n",
    "def parse_audio_files(parent_dir,sub_dirs,file_ext='*.wav'):\n",
    "    features, labels = np.empty((0,193)), np.empty(0)\n",
    "    files = []\n",
    "    print('==DIR', parent_dir)\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        print('====DIR', label, sub_dir)\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            basename = os.path.basename(fn)\n",
    "            try:\n",
    "                mfccs, chroma, mel, contrast,tonnetz = extract_feature(fn)\n",
    "                ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "                features = np.vstack([features,ext_features])\n",
    "                label = basename.split('-')[1]\n",
    "                labels = np.append(labels, label)\n",
    "                files.append(basename)\n",
    "                print(fn, label, ext_features.shape)\n",
    "            except:\n",
    "                print(fn, 'SKIP')\n",
    "            \n",
    "            \n",
    "    return files, np.array(features), np.array(labels, dtype = np.int)\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = 10 # len(np.unique(labels))\n",
    "    one_hot = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot[np.arange(n_labels), labels] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parent_dir = 'audio'\n",
    "\n",
    "sub_dirs = ['data']\n",
    "files, features, labels = parse_audio_files(parent_dir,sub_dirs)\n",
    "print('Audio Data Loading Done')\n",
    "print(\"feature. shape\",features.shape)\n",
    "print(\"label. shape\",labels.shape)\n",
    "\n",
    "\n",
    "labels = one_hot_encode(labels)\n",
    "for f, l in zip(files, labels):\n",
    "    print(f, l)\n",
    "\n",
    "\n",
    "train_test_split = np.random.rand(len(features)) < 0.70\n",
    "train_x = features[train_test_split]\n",
    "train_y = labels[train_test_split]\n",
    "test_x = features[~train_test_split]\n",
    "test_y = labels[~train_test_split]\n",
    "\n",
    "training_epochs = 5000\n",
    "n_dim = features.shape[1]\n",
    "print('DIM', n_dim)\n",
    "n_classes = 10\n",
    "#n_hidden_units_one = 280 \n",
    "#n_hidden_units_two = 300\n",
    "sd = 1 / np.sqrt(n_dim)\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "n_hidden_units_one = 300\n",
    "n_hidden_units_two = 200\n",
    "n_hidden_units_three = 100\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None,n_dim])\n",
    "Y = tf.placeholder(tf.float32,[None,n_classes])\n",
    "\n",
    "W_1 = tf.Variable(tf.random_normal([n_dim, n_hidden_units_one], mean=0, stddev=sd), name=\"w1\")\n",
    "b_1 = tf.Variable(tf.random_normal([n_hidden_units_one], mean=0, stddev=sd), name=\"b1\")\n",
    "h_1 = tf.nn.sigmoid(tf.matmul(X, W_1) + b_1)\n",
    "\n",
    "W_2 = tf.Variable(tf.random_normal([n_hidden_units_one, n_hidden_units_two], mean=0, stddev=sd), name=\"w2\")\n",
    "b_2 = tf.Variable(tf.random_normal([n_hidden_units_two], mean=0, stddev=sd), name=\"b2\")\n",
    "h_2 = tf.nn.tanh(tf.matmul(h_1, W_2) + b_2)\n",
    "\n",
    "W_3 = tf.Variable(tf.random_normal([n_hidden_units_two, n_hidden_units_three], mean=0, stddev=sd), name=\"w3\")\n",
    "b_3 = tf.Variable(tf.random_normal([n_hidden_units_three], mean=0, stddev=sd), name=\"b3\")\n",
    "h_3 = tf.nn.sigmoid(tf.matmul(h_2, W_3) + b_3)\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_hidden_units_three, n_classes], mean=0, stddev=sd), name=\"w\")\n",
    "b = tf.Variable(tf.random_normal([n_classes], mean = 0, stddev=sd), name=\"b\")\n",
    "y_ = tf.nn.softmax(tf.matmul(h_3, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "cost_function = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(y_), reduction_indices=[1])) \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "y_true, y_pred = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(training_epochs):            \n",
    "        _,cost = sess.run([optimizer,cost_function],feed_dict={X:train_x,Y:train_y})\n",
    "        if epoch % 100 == 0:\n",
    "            print(cost)\n",
    "        cost_history = np.append(cost_history,cost)\n",
    "    \n",
    "    y_pred = sess.run(tf.argmax(y_,1),feed_dict={X: test_x})\n",
    "    y_true = sess.run(tf.argmax(test_y,1))\n",
    "    print(\"y_pred,,,\",y_pred.shape)\n",
    "    print(\"y_true,,,\",y_true.shape)\n",
    "    print(\"y_pred>>\",y_pred)\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, \"./sound_trained.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(cost_history)\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.axis([0,training_epochs,0,np.max(cost_history)])\n",
    "plt.show()\n",
    "\n",
    "#p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "#print(\"F-Score:\", round(f,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
